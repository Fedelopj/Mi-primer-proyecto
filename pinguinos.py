# -*- coding: utf-8 -*-
"""pinguinos

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yOlN-YanvC_eNDznl_n1mNFJzUQBxyOD
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import adjusted_rand_score

file_path = "/content/penguins.csv"
out_dir = "analysis_plots"
os.makedirs(out_dir, exist_ok=True)

df = pd.read_csv(file_path)
print("Dimensiones del dataset:", df.shape)
print("\nColumnas y tipos:\n", df.dtypes)
print("\nValores nulos por columna:\n", df.isnull().sum())
print("\nDescripción numérica:\n", df.describe())

num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
print("\nVariables numéricas detectadas:", num_cols)

for col in num_cols:
    plt.figure(figsize=(7,2.5))
    plt.boxplot(df[col].dropna(), vert=False)
    plt.title(f'Boxplot - {col}')
    plt.xlabel(col)
    plt.tight_layout()
    fname = os.path.join(out_dir, f"boxplot_{col}.png")
    plt.savefig(fname)
    plt.close()
    print("Guardado:", fname)

for col in num_cols:
    plt.figure(figsize=(6,3))
    plt.hist(df[col].dropna(), bins=20)
    plt.title(f'Histograma - {col}')
    plt.xlabel(col)
    plt.ylabel('Frecuencia')
    plt.tight_layout()
    fname = os.path.join(out_dir, f"hist_{col}.png")
    plt.savefig(fname)
    plt.close()
    print("Guardado:", fname)

corr = df[num_cols].corr(method='pearson')
plt.figure(figsize=(6,5))
im = plt.imshow(corr, aspect='auto', vmin=-1, vmax=1)
plt.colorbar(im, fraction=0.046, pad=0.04)
plt.xticks(ticks=np.arange(len(num_cols)), labels=num_cols, rotation=45, ha='right')
plt.yticks(ticks=np.arange(len(num_cols)), labels=num_cols)

for i in range(len(num_cols)):
    for j in range(len(num_cols)):
        plt.text(j, i, f"{corr.iloc[i,j]:.2f}", ha='center', va='center', fontsize=9)
plt.title('Mapa de calor: Correlación Pearson')
plt.tight_layout()
heatmap_path = os.path.join(out_dir, "correlation_heatmap.png")
plt.savefig(heatmap_path)
plt.close()
print("Guardado:", heatmap_path)

nulos_df = df[df.isnull().any(axis=1)]
print(f"\nNúmero de filas con al menos un nulo: {nulos_df.shape[0]}")
if nulos_df.shape[0] > 0:
    nulos_csv = os.path.join(out_dir, "filas_con_nulos.csv")
    nulos_df.to_csv(nulos_csv, index=False)
    print("Filas con nulos guardadas en:", nulos_csv)

X = df[num_cols].copy()
X_imputed = X.fillna(X.median())
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

k = 3
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
labels = kmeans.fit_predict(X_scaled)
df['cluster_k3'] = labels

clusters_csv = os.path.join(out_dir, "penguins_with_clusters.csv")
df.to_csv(clusters_csv, index=False)
print("\nEtiquetas de cluster añadidas y dataset guardado en:", clusters_csv)

print("\nConteo por cluster:")
print(df['cluster_k3'].value_counts().sort_index())

print("\nMedias por cluster (numéricas):")
print(df.groupby('cluster_k3')[num_cols].mean())

if 'species' in df.columns:
    crosstab = pd.crosstab(df['species'], df['cluster_k3'])
    crosstab_csv = os.path.join(out_dir, "crosstab_species_cluster.csv")
    crosstab.to_csv(crosstab_csv)
    print("\nTabla cruzada species vs cluster (guardada):", crosstab_csv)
    print(crosstab)
    species_notnull = df['species'].notnull()
    if species_notnull.sum() > 0:
        species_codes = pd.Categorical(df.loc[species_notnull, 'species']).codes
        ari = adjusted_rand_score(species_codes, df.loc[species_notnull, 'cluster_k3'])
        print(f"\nAdjusted Rand Index (clusters vs species) sobre filas con species: {ari:.3f}")
else:
    print("\nNo existe la columna 'species' para comparar.")

try:
    from sklearn.decomposition import PCA
    pca = PCA(n_components=2, random_state=42)
    pc = pca.fit_transform(X_scaled)
    plt.figure(figsize=(7,5))
    for c in sorted(df['cluster_k3'].unique()):
        mask = df['cluster_k3'] == c
        plt.scatter(pc[mask,0], pc[mask,1], label=f"cluster {c}", alpha=0.7, s=30)
    plt.xlabel('PC1')
    plt.ylabel('PC2')
    plt.title('PCA (2 componentes) coloreado por cluster_k3')
    plt.legend()
    pca_path = os.path.join(out_dir, "pca_clusters.png")
    plt.tight_layout()
    plt.savefig(pca_path)
    plt.close()
    print("Guardado:", pca_path)

    if 'species' in df.columns:
        plt.figure(figsize=(7,5))
        species_unique = df['species'].dropna().unique()
        for s in species_unique:
            mask = df['species'] == s
            plt.scatter(pc[mask,0], pc[mask,1], label=str(s), alpha=0.7, s=30)
        plt.xlabel('PC1')
        plt.ylabel('PC2')
        plt.title('PCA (2 componentes) coloreado por species')
        plt.legend()
        pca_species_path = os.path.join(out_dir, "pca_species.png")
        plt.tight_layout()
        plt.savefig(pca_species_path)
        plt.close()
        print("Guardado:", pca_species_path)
except Exception as e:
    print("No se pudo generar PCA:", e)

print("\n--- RESUMEN INTERPRETATIVO RÁPIDO ---")
print("- Hay algunas filas con valores nulos (variables numéricas: 2 nulos aprox., 'sex' tiene más nulos).")
print("- Las variables numéricas muestran correlación especialmente entre flipper_length_mm y body_mass_g.")
print("- KMeans con k=3 genera clusters que separan por tamaño corporal / longitud de aleta; esto concuerda con las especies registradas.")
print("- Se guardaron gráficos y archivos en la carpeta:", out_dir)
print("\nFin del script. Revisa los PNG y CSV generados para tu informe.")